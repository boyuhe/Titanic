{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/magictavern/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.chdir('/Users/magictavern/Documents/kaggkle/all')\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/magictavern/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "train= pd.read_csv('train.csv')\n",
    "full=pd.concat([train,test],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.Fare.fillna(full.Fare.value_counts().index[0],inplace=True)\n",
    "full.Embarked.fillna(full.Embarked.value_counts().index[0],inplace=True)\n",
    "full.Cabin.fillna('None',inplace=True)\n",
    "full.Age.fillna(full.Age.median(),inplace=True)\n",
    "full.Survived.fillna(-1,inplace=True)\n",
    "sex_map={'male':0,'female':1}\n",
    "full.Sex=full.Sex.map(sex_map)\n",
    "def get_t(x):\n",
    "    y=x.split(',')[1].split('.')[0]\n",
    "    return y\n",
    "full.Name=full.Name.map(get_t)\n",
    "title_map=pd.Series(range(len(full.Name.value_counts())),index=full.Name.value_counts().index)\n",
    "full.Name=full.Name.map(title_map)\n",
    "full['Family']=full['SibSp']+full['Parch']\n",
    "del full['Ticket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_map=pd.Series(range(len(full.Cabin.value_counts())),index=full.Cabin.value_counts().index)\n",
    "full['Cabin']=full['Cabin'].map(cabin_map)\n",
    "embarked_map=pd.Series(range(len(full.Embarked.value_counts())),index=full.Embarked.value_counts().index)\n",
    "full['Embarked']=full['Embarked'].map(embarked_map)\n",
    "cat_feature=['Cabin','Embarked','Name','Parch','Pclass','Sex','SibSp','Family']\n",
    "result=full[full['Survived']==-1].pop('PassengerId')\n",
    "del full['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/magictavern/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_data=full[full['Survived']!=-1]\n",
    "test_data=full[full['Survived']==-1]\n",
    "del test_data['Survived']\n",
    "train_data['Survived']=train_data.Survived.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_data.pop('Survived')\n",
    "X_train,X_eval,y_train,y_eval=train_test_split(train_data,y,test_size=0.2,random_state=0)\n",
    "lgb_train = lgb.Dataset(X_train, y_train,free_raw_data=False)\n",
    "lgb_eval = lgb.Dataset(X_eval, y_eval,reference=lgb_train,free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "调参1：num_leaves/max_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/magictavern/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1194: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Cabin', 'Embarked', 'Family', 'Name', 'Parch', 'Pclass', 'Sex', 'SibSp']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'num_leaves': 130, 'max_bin': 255}\n",
      "best cv score: 0.4392241684202651\n",
      "调参2：feature_fraction/min_data_in_leaf\n",
      "best params: {'num_leaves': 130, 'max_bin': 255, 'feature_fraction': 1.0, 'min_data_in_leaf': 30}\n",
      "best cv score: 0.43517037970451905\n",
      "调参3：bagging\n",
      "best params: {'num_leaves': 130, 'max_bin': 255, 'feature_fraction': 1.0, 'min_data_in_leaf': 30, 'bagging_fraction': 1.0, 'bagging_freq': 6}\n",
      "best cv score: 0.43517037970451894\n",
      "调参4：l1/l2\n",
      "best params: {'num_leaves': 130, 'max_bin': 255, 'feature_fraction': 1.0, 'min_data_in_leaf': 30, 'bagging_fraction': 1.0, 'bagging_freq': 6, 'lambda_l1': 1.0, 'lambda_l2': 0.01}\n",
      "best cv score: 0.43462257839522334\n"
     ]
    }
   ],
   "source": [
    "params = {    'boosting_type': 'gbdt', \n",
    "    'objective': 'binary', \n",
    "              'learning_rate': 0.1,\n",
    "          'is_unbalance': True \n",
    "         }\n",
    "params['metrics']='binary_logloss'\n",
    "best_score = float('Inf')\n",
    "best_params = {}\n",
    "cat_feature=['Cabin','Embarked','Name','Parch','Pclass','Sex','SibSp','Family']\n",
    "print(\"调参1：num_leaves/max_bin\")\n",
    "for num_leaves in range(31,131,9):\n",
    "    for max_bin in range(55,256,50):\n",
    "        \n",
    "        params['num_leaves'] = num_leaves\n",
    "        params['max_bin'] = max_bin\n",
    "            \n",
    "        cv_results = lgb.cv(params, lgb_train,num_boost_round=1000, nfold=5,stratified=False,\n",
    "        early_stopping_rounds=50, verbose_eval=False,categorical_feature=cat_feature )\n",
    "            \n",
    "        mean_binary_logloss = pd.Series(cv_results['binary_logloss-mean']).min()\n",
    "            \n",
    "        if mean_binary_logloss <= best_score:\n",
    "            best_score = mean_binary_logloss\n",
    "            best_params['num_leaves'] = num_leaves\n",
    "            best_params['max_bin'] = max_bin\n",
    "                \n",
    "params['num_leaves'] = best_params['num_leaves']\n",
    "params['max_bin'] = best_params['max_bin']\n",
    "\n",
    "print('best params:', best_params)\n",
    "print('best cv score:', best_score)\n",
    "\n",
    "print(\"调参2：feature_fraction/min_data_in_leaf\")\n",
    "for feature_fraction in [0.6,0.8,1.0]:\n",
    "    for min_data_in_leaf in range(20,101,10):\n",
    "        \n",
    "            params['feature_fraction'] =feature_fraction\n",
    "            params['min_data_in_leaf'] = min_data_in_leaf\n",
    "            \n",
    "            cv_results = lgb.cv(params, lgb_train,num_boost_round=1000, nfold=5, stratified=False,\n",
    "            early_stopping_rounds=50, verbose_eval=False,categorical_feature=cat_feature)\n",
    "                    \n",
    "            mean_binary_logloss = pd.Series(cv_results['binary_logloss-mean']).min()\n",
    "            \n",
    "            if mean_binary_logloss <= best_score:\n",
    "                best_score = mean_binary_logloss\n",
    "                best_params['feature_fraction']=feature_fraction\n",
    "                best_params['min_data_in_leaf'] = min_data_in_leaf\n",
    "\n",
    "params['min_data_in_leaf'] = best_params['min_data_in_leaf']\n",
    "params['feature_fraction'] = best_params['feature_fraction']\n",
    "\n",
    "print('best params:', best_params)\n",
    "print('best cv score:', best_score)\n",
    "\n",
    "print(\"调参3：bagging\")\n",
    "for bagging_fraction in [0.6,0.8,1.0]:\n",
    "    for bagging_freq in range(0,11,1):\n",
    "        params['bagging_fraction'] = bagging_fraction\n",
    "        params['bagging_freq'] = bagging_freq\n",
    "            \n",
    "        cv_results = lgb.cv(params, lgb_train,num_boost_round=1000, nfold=5,stratified=False,\n",
    "        early_stopping_rounds=50, verbose_eval=False,categorical_feature=cat_feature)\n",
    "                    \n",
    "        mean_binary_logloss = pd.Series(cv_results['binary_logloss-mean']).min()\n",
    "            \n",
    "        if mean_binary_logloss <= best_score:\n",
    "            best_score = mean_binary_logloss\n",
    "            best_params['bagging_fraction'] = bagging_fraction\n",
    "            best_params['bagging_freq'] = bagging_freq\n",
    "\n",
    "params['bagging_fraction'] = best_params['bagging_fraction']\n",
    "params['bagging_freq'] = best_params['bagging_freq']\n",
    "\n",
    "print('best params:', best_params)\n",
    "print('best cv score:', best_score)\n",
    "\n",
    "print(\"调参4：l1/l2\")\n",
    "for lambda_l1 in [0.0,0.01,0.1,1.0,10,100,1000]:\n",
    "    for lambda_l2 in [0.0,0.01,0.1,1.0,10,100,1000]:\n",
    "        \n",
    "        params['lambda_l1'] = lambda_l1\n",
    "        params['lambda_l2'] = lambda_l2\n",
    "            \n",
    "        cv_results = lgb.cv(params, lgb_train,num_boost_round=1000, nfold=5, stratified=False,\n",
    "        early_stopping_rounds=50, verbose_eval=False,categorical_feature=cat_feature)\n",
    "                    \n",
    "        mean_binary_logloss = pd.Series(cv_results['binary_logloss-mean']).min()\n",
    "            \n",
    "        if mean_binary_logloss <= best_score:\n",
    "            best_score = mean_binary_logloss\n",
    "            best_params['lambda_l1'] = lambda_l1\n",
    "            best_params['lambda_l2'] = lambda_l2\n",
    "\n",
    "params['lambda_l1'] = best_params['lambda_l1']\n",
    "params['lambda_l2'] = best_params['lambda_l2']\n",
    "\n",
    "print('best params:', best_params)\n",
    "print('best cv score:', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['learning_rate']=0.01\n",
    "lgbm=lgb.train(\n",
    "          params,                     # 参数字典\n",
    "          lgb_train,                  # 训练集\n",
    "          valid_sets=[lgb_train,lgb_eval],\n",
    "    valid_names=['train','evals'],\n",
    "          num_boost_round=2000,       # 迭代次数\n",
    "          early_stopping_rounds=50,# 早停次数\n",
    "         verbose_eval=False,categorical_feature=cat_feature\n",
    "          )\n",
    "feat_importance=pd.Series(lgbm.feature_importance(),index=test_data.columns)\n",
    "y_pred=lgbm.predict(test_data) # 输出概率\n",
    "pre_y=pd.Series(y_pred,index=result.values)\n",
    "result=pre_y.map(lambda x: 1 if x >0.5 else 0).reset_index()\n",
    "result.rename(columns={'index':'PassengerId',0:'Survived'},inplace=True)\n",
    "result.to_csv('titanic_pred20.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
